apiVersion: apps/v1
kind: Deployment
metadata:
  name: spark-thrift-server
  namespace: compute
spec:
  replicas: 1
  selector:
    matchLabels:
      app: spark-thrift-server
  template:
    metadata:
      labels:
        app: spark-thrift-server
    spec:
      serviceAccountName: spark
      containers:
      - name: thrift
        image: spark:3.5.7-scala2.12-java17-python3-ubuntu
        imagePullPolicy: IfNotPresent
        command: ["/bin/bash", "-c"]
        args:
          - |
            echo "Starting Spark Thrift Server (Delta + MinIO + Hive)..."
            /opt/spark/sbin/start-thriftserver.sh \
              --master k8s://https://kubernetes.default.svc \
              --deploy-mode client \
              --conf spark.kubernetes.container.image=apache/spark:3.5.1 \
              --conf spark.executor.instances=2 \
              --conf spark.sql.extensions=io.delta.sql.DeltaSparkSessionExtension \
              --conf spark.sql.catalog.spark_catalog=org.apache.spark.sql.delta.catalog.DeltaCatalog \
              --conf spark.sql.catalogImplementation=hive \
              --conf spark.hadoop.hive.metastore.uris=thrift://hive-metastore.metastore.svc.cluster.local:9083 \
              --conf spark.hadoop.fs.s3a.endpoint=http://minio-0.storage.svc.cluster.local:9000 \
              --conf spark.hadoop.fs.s3a.access.key=minio \
              --conf spark.hadoop.fs.s3a.secret.key=minio123 \
              --conf spark.hadoop.fs.s3a.path.style.access=true \
              --conf spark.hadoop.fs.s3a.connection.ssl.enabled=false \
              --conf spark.sql.warehouse.dir=s3a://warehouse/ \
              --conf spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem \
              --packages io.delta:delta-spark_2.12:3.2.0,org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.262 \
              --driver-memory 2g --executor-memory 2g \
              --driver-cores 1 --executor-cores 1
            echo "Spark Thrift Server started."
            # giữ container sống foreground để không exit
            tail -f /dev/null
        ports:
          - name: thrift
            containerPort: 10000
        resources:
          requests:
            cpu: "1"
            memory: "2Gi"
          limits:
            cpu: "2"
            memory: "4Gi"
---
apiVersion: v1
kind: Service
metadata:
  name: spark-thrift-svc
  namespace: compute
spec:
  type: ClusterIP
  selector:
    app: spark-thrift-server
  ports:
    - name: thrift
      port: 10000
      targetPort: thrift
