apiVersion: apps/v1
kind: Deployment
metadata:
  name: spark-thrift-server
  namespace: compute
spec:
  replicas: 1
  selector:
    matchLabels:
      app: spark-thrift-server
  template:
    metadata:
      labels:
        app: spark-thrift-server
    spec:
      serviceAccountName: spark
      containers:
      - name: thrift
        image: spark:3.5.7-scala2.12-java17-python3-ubuntu
        command:
          - /opt/spark/bin/spark-submit
        args:
          - --master
          - k8s://https://kubernetes.default.svc
          - --conf spark.kubernetes.namespace=compute \
          - --conf spark.kubernetes.authenticate.driver.serviceAccountName=spark \
          - --conf spark.sql.extensions=io.delta.sql.DeltaSparkSessionExtension
          - --conf spark.sql.catalog.spark_catalog=org.apache.spark.sql.delta.catalog.DeltaCatalog
          - --conf spark.sql.catalogImplementation=hive
          - --conf spark.hadoop.hive.metastore.uris=thrift://hive-metastore.metastore.svc.cluster.local:9083
          - --conf spark.hadoop.fs.s3a.endpoint=http://minio-0.storage.svc.cluster.local:9000
          - --conf spark.hadoop.fs.s3a.access.key=minioadmin
          - --conf spark.hadoop.fs.s3a.secret.key=minio@demo!
          - --conf spark.hadoop.fs.s3a.path.style.access=true
          - --conf spark.hadoop.fs.s3a.connection.ssl.enabled=false
          - --conf spark.sql.warehouse.dir=s3a://warehouse/
          - --conf spark.eventLog.dir=s3a://spark-logs/events
          - --conf spark.driver.extraJavaOptions="-Divy.cache.dir=/tmp -Divy.home=/tmp"
          - --packages io.delta:delta-spark_2.12:3.2.0,org.apache.hadoop:hadoop-aws:3.3.4,org.apache.hadoop:hadoop-common:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.262
          - --class org.apache.spark.sql.hive.thriftserver.HiveThriftServer2
        ports:
          - containerPort: 10000
            name: thrift
        resources:
          requests:
            cpu: 1
            memory: 2Gi
---
apiVersion: v1
kind: Service
metadata:
  name: spark-thrift-svc
  namespace: compute
spec:
  type: ClusterIP
  selector:
    app: spark-thrift-server
  ports:
    - name: thrift
      port: 10000
      targetPort: thrift
