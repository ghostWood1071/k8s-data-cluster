ingress:
  enabled: false

executor: "KubernetesExecutor"

cleanup:
  enabled: true

data:
  metadataConnection:
    user: airflow
    pass: airflow
    protocol: postgresql
    host: airflow-postgresql.orchestration.svc.cluster.local
    port: 5432
    db: airflow
    sslmode: disable


postgresql:
  enabled: false
  image:
    registry: docker.io
    repository: bitnami/postgresql
    tag: "latest"
    pullPolicy: IfNotPresent
  auth:
    username: "airflow"
    password: "airflow"
    enablePostgresUser: false
  primary:
    extraEnvVars: # <-- inject ENV để dùng trong script
      - name: AIRFLOW_USER
        value: "airflow"
      - name: AIRFLOW_PASSWORD
        value: "airflow"
      - name: AIRFLOW_DB
        value: "airflow"
    initdb:
      # scripts nhận cả .sh lẫn .sql; Bitnami sẽ chạy khi PVC TRỐNG
      scripts:
        00-airflow.sh: |
          #!/bin/bash
          set -euo pipefail
          # superuser password cho postgres
          export PGPASSWORD="${POSTGRESQL_POSTGRES_PASSWORD:-${POSTGRES_PASSWORD:-adminpass}}"
          
          # Giá trị mặc định nếu ENV không có
          : "${AIRFLOW_USER:=airflow}"
          : "${AIRFLOW_PASSWORD:=airflow}"
          : "${AIRFLOW_DB:=airflow}"
          
          # Dùng psql -v để truyền biến an toàn vào DO block (format %I/%L tránh injection)
          psql -v ON_ERROR_STOP=1 -U postgres -d postgres \
               -v air_user="$AIRFLOW_USER" \
               -v air_pw="$AIRFLOW_PASSWORD" \
               -v air_db="$AIRFLOW_DB" <<'SQL'
          DO $do$
          DECLARE
            u text := :'air_user';
            pw text := :'air_pw';
            db text := :'air_db';
          BEGIN
            IF NOT EXISTS (SELECT 1 FROM pg_roles WHERE rolname = u) THEN
              EXECUTE format('CREATE ROLE %I LOGIN PASSWORD %L', u, pw);
            END IF;
          
            IF NOT EXISTS (SELECT 1 FROM pg_database WHERE datname = db) THEN
              EXECUTE format('CREATE DATABASE %I OWNER %I', db, u);
            END IF;
          
            -- Quyền/owner tối thiểu cho Airflow
            EXECUTE format('GRANT ALL PRIVILEGES ON DATABASE %I TO %I', db, u);
          END
          $do$;
          
          \connect :'air_db'
          ALTER SCHEMA public OWNER TO :"air_user";
          ALTER ROLE :"air_user" SET search_path = public;
          ALTER DEFAULT PRIVILEGES IN SCHEMA public GRANT ALL ON TABLES    TO :"air_user";
          ALTER DEFAULT PRIVILEGES IN SCHEMA public GRANT ALL ON SEQUENCES TO :"air_user";
          ALTER DEFAULT PRIVILEGES IN SCHEMA public GRANT ALL ON FUNCTIONS TO :"air_user";
          SQL
# Default airflow repository -- overridden by all the specific images below
defaultAirflowRepository: ghostwood/airflow
# Default airflow tag to deploy
defaultAirflowTag: "2.0.1"
# Default airflow digest. If specified, it takes precedence over tag
defaultAirflowDigest: ~
# Airflow version (Used to make some decisions based on Airflow Version being deployed)
airflowVersion: "2.10.0"

dagProcessor:
  enabled: ~

airflow:
  kubernetesPodTemplate:
    extraPipPackages:
      - "apache-airflow-providers-amazon==10.3.0"

config:
  logging:
    remoteLogging: true
    remoteLogConnId: minio_conn
    remoteBaseLogFolder: s3a://airflow-logs
    encryptS3Logs: false
  core:
    dags_folder: '{{ include "airflow_dags" . }}'
    # This is ignored when used with the official Docker image
    load_examples: 'True'
    executor: '{{ .Values.executor }}'
    # For Airflow 1.10, backward compatibility; moved to [logging] in 2.0
    colored_console_log: 'False'
    remote_logging: '{{- ternary "True" "False" (or .Values.elasticsearch.enabled .Values.opensearch.enabled) }}'
  kubernetes:
    namespace: '{{ .Release.Namespace }}'
    # The following `airflow_` entries are for Airflow 1, and can be removed when it is no longer supported.
    airflow_configmap: '{{ include "airflow_config" . }}'
    airflow_local_settings_configmap: '{{ include "airflow_config" . }}'
    pod_template_file: '{{ include "airflow_pod_template_file" . }}/pod_template_file.yaml'
    worker_container_repository: '{{ .Values.images.airflow.repository | default .Values.defaultAirflowRepository }}'
    worker_container_tag: '{{ .Values.images.airflow.tag | default .Values.defaultAirflowTag }}'
    multi_namespace_mode: '{{ ternary "True" "False" .Values.multiNamespaceMode }}'
  # The `kubernetes_executor` section duplicates the `kubernetes` section in Airflow >= 2.5.0 due to an airflow.cfg schema change.
  kubernetes_executor:
    namespace: '{{ .Release.Namespace }}'
    pod_template_file: '{{ include "airflow_pod_template_file" . }}/pod_template_file.yaml'
    worker_container_repository: '{{ .Values.images.airflow.repository | default .Values.defaultAirflowRepository }}'
    worker_container_tag: '{{ .Values.images.airflow.tag | default .Values.defaultAirflowTag }}'
    multi_namespace_mode: '{{ ternary "True" "False" .Values.multiNamespaceMode }}'
  dag_processor:
    refresh_interval: 30
worker:
  persistence:
    enabled: true
    size: 1Gi
triggerer:
  enabled: true
  persistence:
    enabled: false
    size: 1Gi
dags:
  persistence:
    annotations: {}
    # Enable persistent volume for storing dags
    enabled: true
    # Volume size for dags
    size: 1Gi
    # If using a custom storageClass, pass name here
    # storageClassName: longhorn
    # access mode of the persistent volume
    accessMode: ReadWriteMany
    ## the name of an existing PVC to use
    existingClaim:
    ## optional subpath for dag volume mount
    subPath: ~
  gitSync:
    enabled: false
    repo: https://github.com/apache/airflow.git
    branch: v2-11-stable
    rev: HEAD
    ref: v2-11-stable
    depth: 1
    maxFailures: 0
    subPath: "tests/dags"
redis:
  enabled: true
logs:
  persistence:
    enabled: true
    size: 1Gi
